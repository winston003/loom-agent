"""Multi-turn voice conversation demo.

Demonstrates Phase 5 (User Story 3) features:
- Multi-turn conversation tracking
- Context preservation across turns
- Automatic compression after 10 turns
- Per-speaker context isolation
- Idle timeout management

Usage:
    python examples/voice_companion/multi_turn_voice.py

Simulates a 5-turn conversation with context retention.
"""

import asyncio
from loom.adapters.audio import AudioAdapter, AudioAdapterConfig
from datetime import datetime


async def demo_multi_turn_conversation():
    """Demonstrate multi-turn conversation with context management."""
    
    print("=" * 60)
    print("Multi-turn Conversation Demo (Phase 5 - User Story 3)")
    print("=" * 60)
    
    # Step 1: Initialize audio adapter
    print("\n[Step 1] Initializing audio adapter...")
    config = AudioAdapterConfig(
        host="127.0.0.1",
        port=8765,
        vad_threshold=0.5,
        sample_rate=16000,
    )
    adapter = AudioAdapter(config)
    await adapter.start()
    print("âœ“ Audio adapter started")
    
    # Step 2: Create session
    print("\n[Step 2] Creating audio session...")
    session_id = await adapter.session_manager.create_session(device_id="xiaozhi-demo-001")
    print(f"âœ“ Session created: {session_id}")
    
    # Step 3: Simulate multi-turn conversation
    print("\n[Step 3] Simulating 5-turn conversation...")
    
    conversations = [
        {
            "user": "ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ",
            "agent": "ä»Šå¤©åŒ—äº¬å¤©æ°”æ™´æœ—ï¼Œæ¸©åº¦ 22Â°Cï¼Œé€‚åˆå¤–å‡ºæ´»åŠ¨ã€‚",
            "speaker_id": "speaker_001",
        },
        {
            "user": "æ˜å¤©å‘¢ï¼Ÿ",  # ç®€åŒ–é—®æ³• - ä¾èµ–ä¸Šä¸‹æ–‡ç†è§£
            "agent": "æ˜å¤©é¢„è®¡å¤šäº‘ï¼Œæ¸©åº¦ 20Â°Cï¼Œæœ‰å°é›¨å¯èƒ½ï¼Œå»ºè®®å¸¦ä¼ã€‚",
            "speaker_id": "speaker_001",
        },
        {
            "user": "åå¤©ä¼šä¸‹é›¨å—ï¼Ÿ",  # ç»§ç»­å¤©æ°”ä¸»é¢˜
            "agent": "åå¤©è½¬æ™´ï¼Œæ¸©åº¦å›å‡åˆ° 24Â°Cï¼Œæ— é™é›¨ã€‚",
            "speaker_id": "speaker_001",
        },
        {
            "user": "è¿™å‘¨æœ«å»å“ªç©æ¯”è¾ƒå¥½ï¼Ÿ",  # åŸºäºå‰é¢å¤©æ°”ä¿¡æ¯
            "agent": "æ ¹æ®å¤©æ°”é¢„æŠ¥ï¼Œå‘¨å…­å¤©æ°”æœ€å¥½ï¼Œæ¨èå»é¢å’Œå›­æˆ–è€…æ•…å®«æ¸¸è§ˆã€‚",
            "speaker_id": "speaker_001",
        },
        {
            "user": "å¥½çš„ï¼Œå¸®æˆ‘è®¾ç½®å‘¨å…­ä¸Šåˆçš„é—¹é’Ÿ",  # å»¶ç»­è®¡åˆ’
            "agent": "å·²è®¾ç½®å‘¨å…­ä¸Šåˆ 8:00 é—¹é’Ÿï¼Œç¥æ‚¨æ¸¸ç©æ„‰å¿«ï¼",
            "speaker_id": "speaker_001",
        },
    ]
    
    for i, conv in enumerate(conversations, 1):
        print(f"\n--- Turn {i} ---")
        print(f"ğŸ‘¤ User: {conv['user']}")
        
        # Add conversation turn (simulating ASR + Agent response)
        adapter.session_manager.add_conversation_turn(
            session_id=session_id,
            user_text=conv["user"],
            agent_response=conv["agent"],
            speaker_id=conv["speaker_id"],
            metadata={"turn_number": i},
        )
        
        print(f"ğŸ¤– Agent: {conv['agent']}")
        
        # Check session state
        session = adapter.session_manager.get_session(session_id)
        print(f"ğŸ“Š Turn count: {session.turn_count}")
    
    # Step 4: Retrieve conversation context
    print("\n[Step 4] Retrieving conversation context...")
    
    session = adapter.session_manager.get_session(session_id)
    
    # Get full context (no compression at 5 turns)
    context = adapter.get_conversation_context(
        session_id=session_id,
        system_prompt="You are Xiaozhi, a helpful voice assistant.",
        compress=False,
    )
    
    print(f"\nğŸ“ Full context ({len(context)} chars):")
    print(context)
    
    # Step 5: Simulate 10 more turns to trigger compression
    print("\n[Step 5] Adding 10 more turns to trigger compression...")
    
    for i in range(6, 16):
        adapter.session_manager.add_conversation_turn(
            session_id=session_id,
            user_text=f"è¿™æ˜¯ç¬¬ {i} è½®æµ‹è¯•å¯¹è¯",
            agent_response=f"æ”¶åˆ°ç¬¬ {i} è½®æ¶ˆæ¯",
            speaker_id="speaker_001",
        )
    
    session = adapter.session_manager.get_session(session_id)
    print(f"âœ“ Total turns: {session.turn_count}")
    print(f"âœ“ Compression needed: {adapter.context_manager.should_compress(session.turn_count)}")
    
    # Get compressed context
    compressed_context = adapter.get_conversation_context(
        session_id=session_id,
        system_prompt="You are Xiaozhi, a helpful voice assistant.",
        compress=True,
    )
    
    print(f"\nğŸ“¦ Compressed context ({len(compressed_context)} chars):")
    print(compressed_context)
    
    # Step 6: Test idle timeout
    print("\n[Step 6] Testing idle timeout...")
    
    # Check current idle status
    is_idle = adapter.session_manager.check_idle_timeout(session_id, timeout_seconds=0)
    print(f"âœ“ Session idle (0s threshold): {is_idle}")
    
    # Simulate activity update
    session.last_activity_at = datetime.utcnow()
    is_idle = adapter.session_manager.check_idle_timeout(session_id, timeout_seconds=30)
    print(f"âœ“ Session idle (30s threshold): {is_idle}")
    
    # Step 7: Test per-speaker context isolation
    print("\n[Step 7] Testing per-speaker context isolation...")
    
    # Add turn from different speaker
    adapter.session_manager.add_conversation_turn(
        session_id=session_id,
        user_text="æˆ‘æ˜¯è®¿å®¢ï¼Œè¯·å¸®æˆ‘æŸ¥è¯¢å¤©æ°”",
        agent_response="å¥½çš„ï¼Œè¯·é—®æ‚¨è¦æŸ¥è¯¢å“ªä¸ªåŸå¸‚ï¼Ÿ",
        speaker_id="speaker_002",  # Different speaker
    )
    
    # Get context for speaker_001 only
    speaker1_context = adapter.context_manager.assemble_context(
        conversation_history=session.conversation_history,
        speaker_id="speaker_001",
        compress=False,
    )
    
    # Get context for speaker_002 only
    speaker2_context = adapter.context_manager.assemble_context(
        conversation_history=session.conversation_history,
        speaker_id="speaker_002",
        compress=False,
    )
    
    print(f"âœ“ Speaker 1 context: {len(speaker1_context)} chars (15 turns)")
    print(f"âœ“ Speaker 2 context: {len(speaker2_context)} chars (1 turn)")
    
    # Step 8: Cleanup
    print("\n[Step 8] Cleaning up...")
    await adapter.session_manager.close_session(session_id)
    await adapter.stop()
    print("âœ“ Session closed and adapter stopped")
    
    print("\n" + "=" * 60)
    print("Multi-turn conversation demo completed! âœ…")
    print("=" * 60)
    print("\nKey features demonstrated:")
    print("âœ“ Multi-turn conversation tracking (T076-T078)")
    print("âœ“ Context assembly and compression (T079-T081)")
    print("âœ“ Per-speaker context isolation (T082)")
    print("âœ“ Idle timeout management (T085)")
    print("âœ“ Auto-compression after 10 turns (T086)")


if __name__ == "__main__":
    asyncio.run(demo_multi_turn_conversation())
