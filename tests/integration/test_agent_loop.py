import asyncio
from typing import Any

import pytest

from loom.api.main import LoomApp
from loom.interfaces.llm import LLMProvider, LLMResponse
from loom.node.agent import AgentNode
from loom.node.tool import ToolNode
from loom.protocol.cloudevents import CloudEvent
from loom.protocol.mcp import MCPToolDefinition as ToolDefinition


class MockSequenceLLM(LLMProvider):
    def __init__(self, responses: list[LLMResponse]):
         self.responses = responses
         self.calls = 0

    async def chat(self, messages: list[Any], tools: list[Any] = None) -> LLMResponse:
        if self.calls < len(self.responses):
            resp = self.responses[self.calls]
            self.calls += 1
            return resp
        return LLMResponse(content="Limit reached")

    async def stream_chat(self, *args, **kwargs):
        pass

class MockTool(ToolNode):
    async def process(self, event: CloudEvent) -> Any:
        return {"result": "Tool success"}

@pytest.mark.asyncio
async def test_agent_react_loop():
    app = LoomApp()

    # Define tool
    tool_def = ToolDefinition(name="test_tool", description="test tool", inputSchema={})
    tool = MockTool(node_id="tool", dispatcher=app.dispatcher, tool_def=tool_def, func=lambda _: "success")


    # Mock LLM sequence
    # 1. Call tool
    resp1 = LLMResponse(content="", tool_calls=[{"name": "test_tool", "arguments": {}}])
    # 2. Final answer
    resp2 = LLMResponse(content="Final Answer")

    provider = MockSequenceLLM([resp1, resp2])

    AgentNode(
        node_id="agent",
        dispatcher=app.dispatcher,
        tools=[tool],
        provider=provider
    )

    # Run
    # app.run uses target="node/agent"
    # We must ensure agent knows about the tool node?
    # AgentNode init: known_tools={name: tool}.
    # Yes, we passed tools=[tool].

    # Allow logic to settle?
    await asyncio.sleep(0.1)

    # Need to subscribe tool to "node.request/tool" if not already?
    # ToolNode.__init__ subscribes to its id.
    # AgentNode calls subject=target_tool.source_uri (which is based on node_id).

    result = await app.run("Do task", target="node/agent")

    assert result["response"] == "Final Answer"
    assert result["iterations"] == 2
    assert provider.calls == 2

@pytest.mark.asyncio
async def test_max_iterations():
    app = LoomApp()

    # Mock infinite tool loops
    resp_loop = LLMResponse(content="", tool_calls=[{"name": "test_tool", "arguments": {}}])

    # Infinite provider
    class InfiniteLLM(LLMProvider):
        async def chat(self, *args, **kwargs):
            return resp_loop
        async def stream_chat(self, *args, **kwargs): pass

    tool_def = ToolDefinition(name="test_tool", description="test", inputSchema={})
    tool = MockTool(node_id="tool", dispatcher=app.dispatcher, tool_def=tool_def, func=lambda _: "success")

    provider = InfiniteLLM()

    agent = AgentNode(
        node_id="agent_loop",
        dispatcher=app.dispatcher,
        tools=[tool],
        provider=provider
    )

    await asyncio.sleep(0.1)

    # Run with limited iterations
    # How to pass max_iterations via app.run?
    # app.run(task="...", max_iterations=2) -> not supported in signature yet.
    # app.run creates event with data={"task": ...}
    # We can rely on default for now (5) or add param.

    # Let's bypass app.run for precise control or trust default 5.
    event = CloudEvent.create(
        source="user",
        type="node.request",
        data={"task": "Loop", "max_iterations": 3},
        subject="node/agent_loop"
    )

    result = await agent.process(event)

    assert "Error: Maximum iterations reached" in result["response"]
    assert result["iterations"] == 3
